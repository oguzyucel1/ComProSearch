import time
import urllib.parse
import json
import os
from urllib.parse import urljoin, urlparse, parse_qs
from playwright.sync_api import sync_playwright
from scripts.shared.supabase_client import supabase

BASE_URL = "https://www.bayinet.com.tr/"

# --- Supabase Kaydetme ---
def save_products_to_supabase(products, batch_size=50):
    if not products or not supabase:
        print("âŒ Supabase client eksik veya Ã¼rÃ¼n listesi boÅŸ. KayÄ±t atlandÄ±.")
        return

    for i in range(0, len(products), batch_size):
        chunk = products[i:i+batch_size]
        for attempt in range(3):
            try:
                data = (
                    supabase.table("bayinet_products")
                    .upsert(chunk, on_conflict="product_id")
                    .execute()
                )
                print(f"âœ… DB'ye {len(data.data)} Ã¼rÃ¼n yazÄ±ldÄ± (chunk {i//batch_size+1})")
                break
            except Exception as e:
                print(f"âš ï¸ Supabase error (chunk {i//batch_size+1}), retry {attempt+1}/3: {e}")
                time.sleep(5)

# --- Scraper (Playwright DOM tabanlÄ±) ---
def scrape_all_pages(page, category_id, max_pages=200):
    for page_num in range(max_pages):
        search_model = {
            "SelectedProperties": [],
            "SelectedPropertyGroups": [],
            "AllProp": False,
            "PageNumber": page_num,
            "VisibleProductCount": "36",
            "SearchTextInProducts": "",
            "Categories": [category_id],
            "CategoriesLevel4": [],
            "CategoriesLevel2": [],
            "Brands": [],
            "PropertyGroups": [],
            "Properties": [],
            "StoragePlace": "2001",
            "Sorting": "en-dusuk-fiyat",
            "IsStockOnly": False,
            "AllStoragePlaces": False,
            "WithPropertiesAggregation": False,
            "WithPropertyGroupAggregation": False,
            "SearchCategoryId": category_id,
            "MaxPrice": {"Price": 0, "SelectedPrice": 0, "Currency": ""},
            "MinPrice": {"Price": 0, "SelectedPrice": 0, "Currency": ""},
            "IsSubscription": "false",
            "IsN11": False
        }

        url = f"{BASE_URL}Product/Index?searchModel={urllib.parse.quote(json.dumps(search_model, ensure_ascii=False))}"
        page.goto(url)
        page.wait_for_load_state("networkidle")

        product_divs = page.locator("div.product-list__item.grid-item")
        count = product_divs.count()

        if count == 0:
            print(f"â›”ï¸ Kategori {category_id}, Sayfa {page_num}: Ã¼rÃ¼n yok, durdu.")
            break

        products = []
        for i in range(count):
            try:
                link_tag = product_divs.nth(i).locator("h5 a")
                product_name = link_tag.inner_text().strip()
                product_url_absolute = urljoin(BASE_URL, link_tag.get_attribute("href"))
                product_id = parse_qs(urlparse(product_url_absolute).query).get("ProductId", [None])[0]

                price_value, price_display = 0.0, "BelirtilmemiÅŸ"
                price_tag = product_divs.nth(i).locator("strong.fiyatTooltip.pointer")
                if price_tag.count() > 0:
                    data_price = price_tag.first.get_attribute("data-price")
                    if data_price:
                        price_value = float(data_price.replace(",", "."))
                        price_display = f"{price_value:.2f} USD + %20 KDV"

                stock_divs = product_divs.nth(i).locator("span.stock-status")
                stock_info = " | ".join([
                    stock_divs.nth(j).inner_text().strip() for j in range(stock_divs.count())
                ]) if stock_divs.count() > 0 else "BelirtilmemiÅŸ"

                products.append({
                    "product_id": product_id,
                    "name": product_name,
                    "url": product_url_absolute,
                    "category_id": category_id,
                    "price": price_value,
                    "price_display": price_display,
                    "stock_info": stock_info,
                    "last_updated": time.strftime("%Y-%m-%d %H:%M:%S")
                })
            except Exception as e:
                print(f"âš ï¸ ÃœrÃ¼n ayrÄ±ÅŸtÄ±rma hatasÄ± (Kategori {category_id}, Sayfa {page_num}): {e}")

        print(f"âœ… Kategori {category_id}, Sayfa {page_num}: {count} Ã¼rÃ¼n bulundu.")

        # ğŸ”¥ Tek seferde DB'ye yaz
        try:
            data = supabase.table("bayinet_products").upsert(products, on_conflict="product_id").execute()
            print(f"ğŸ’¾ DB'ye {len(data.data)} Ã¼rÃ¼n yazÄ±ldÄ± (Kategori {category_id}, Sayfa {page_num})")
        except Exception as e:
            print(f"âŒ DB kaydÄ± hatasÄ± (Kategori {category_id}, Sayfa {page_num}): {e}")

        time.sleep(1)



def get_and_clear_otp(timeout=180, poll_interval=5):
    """
    Supabase'den OTP'yi bekleyerek Ã§eker ve veritabanÄ±ndan siler.
    """
    start_time = time.time()
    
    print(f"â³ {timeout} saniye boyunca DB'den OTP bekleniyor...")

    while time.time() - start_time < timeout:
        try:
            # 1. Kontrol: OTP var mÄ±? (otp_code sÃ¼tununu oku)
            response = supabase.table(OTP_TABLE).select("otp_code").limit(1).execute()
            
            # response.data, Supabase'den gelen bir liste olmalÄ±dÄ±r.
            if response.data and response.data[0] and response.data[0].get("otp_code"):
                otp_code = response.data[0]["otp_code"]
                print(f"âœ… OTP bulundu. ({int(time.time() - start_time)} saniye bekleme)")

                # 2. Temizlik: OTP'yi veritabanÄ±ndan hemen sil
                # OTP'yi sildiÄŸimizden emin olmak iÃ§in deÄŸeri eÅŸleÅŸtirerek siliyoruz
                delete_response = supabase.table(OTP_TABLE).delete().eq("otp_code", otp_code).execute()
                print(f"ğŸ—‘ï¸ OTP veritabanÄ±ndan silindi. Silinen satÄ±r sayÄ±sÄ±: {len(delete_response.data)}")

                return otp_code
            
        except Exception as e:
            # Supabase'e eriÅŸim hatasÄ± olabilir
            print(f"âš ï¸ Supabase OTP sorgu/silme hatasÄ±: {e}")
            
        # Bekle ve tekrar dene (Polling)
        time.sleep(poll_interval)
        
    # Zaman aÅŸÄ±mÄ±
    raise TimeoutError(f"ğŸš¨ OTP {timeout} saniye iÃ§inde girilmedi, iÅŸlem iptal edildi.")


def manual_login_and_get_session(p):
    
    CUSTOMER_CODE = os.getenv("BAYINET_CUSTOMER_CODE")
    EMAIL = os.getenv("BAYINET_EMAIL")
    PASSWORD = os.getenv("BAYINET_PASSWORD")

    if not all([CUSTOMER_CODE, EMAIL, PASSWORD]):
        raise RuntimeError("ğŸš¨ GiriÅŸ bilgileri eksik (env BAYINET_CUSTOMER_CODE, EMAIL, PASSWORD)!")

    # GH Actions'ta Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z iÃ§in headless=True kalmalÄ±
    browser = p.chromium.launch(headless=True, slow_mo=50) 
    context = browser.new_context()
    page = context.new_page()
    
    # page.goto'ya timeout ve load_state parametrelerini ekleyerek daha agresif bir bekleme uygulayÄ±n
    page.goto(
        f"{BASE_URL}Login", 
        wait_until="domcontentloaded",  # Ä°lk olarak sadece DOM iÃ§eriÄŸinin yÃ¼klenmesini bekle
        timeout=60000                   # Bu adÄ±m iÃ§in bekleme sÃ¼resini 1 dakikaya Ã§Ä±kar
    )

    # Bu bekleme artÄ±k opsiyonel, ancak aÄŸÄ±n durmasÄ±nÄ± garanti etmek iÃ§in kalmalÄ±:
    page.wait_for_load_state("networkidle", timeout=30000) 

    print("â¡ï¸ Login formu yÃ¼kleniyor (AÄŸ boÅŸta)...") 
    
    # SeÃ§iciniz:
    INPUT_SELECTOR = "input" 
    
    # Ä°lk input'un sayfada gÃ¶rÃ¼nmesini beklerken:
    # state='visible' yerine state='attached' deneyerek sadece DOM'a eklenmesini bekleyelim
    page.wait_for_selector(INPUT_SELECTOR, state='attached', timeout=20000) 
    print("âœ… Input selector bulundu.")

    # Kod / Mail / Åifre doldurma adÄ±mÄ±nda da locator'Ä± basitleÅŸtiriyoruz:
    # Playwright'ta 'locator' ile direkt olarak 'input'larÄ± hedeflemek daha doÄŸru ve kararlÄ±dÄ±r.
    
    # TÃ¼m input'larÄ± al (MÃ¼ÅŸteri Kodu, E-posta, Åifre)
    login_inputs = page.locator(INPUT_SELECTOR) 

    # MÃ¼ÅŸteri Kodu (0. index)
    login_inputs.nth(0).fill(CUSTOMER_CODE, delay=50) 
    
    # E-posta (1. index)
    login_inputs.nth(1).fill(EMAIL, delay=50) 
    
    # Åifre (2. index)
    login_inputs.nth(2).fill(PASSWORD, delay=50) 
    
    print("âœ… GiriÅŸ bilgileri dolduruldu.")

    # GiriÅŸ Yap butonuna tÄ±klama adÄ±mÄ± aynÄ± kalÄ±r
    page.locator("button:has-text('GiriÅŸ Yap')").click()
    page.wait_for_load_state("networkidle")
    print("â¡ï¸ GiriÅŸ yapÄ±ldÄ±, OTP ekranÄ± bekleniyor...")

    # OTP ekranÄ± yÃ¼klendiÄŸinde, UI'dan giriÅŸi beklemeye baÅŸla
    page.wait_for_selector("div.css-1phe0ka input", timeout=120000)
    print("âœ¨ OTP GiriÅŸ EkranÄ± YÃ¼klendi. DB'den kod Ã§ekiliyor.")

    # ğŸ”¥ BURASI DEÄÄ°ÅTÄ°: DB'den OTP'yi bekle ve Ã§ek
    try:
        otp_code = get_and_clear_otp(timeout=180, poll_interval=5) # 3 dakika bekle
    except TimeoutError as e:
        # Zaman aÅŸÄ±mÄ±nda tarayÄ±cÄ±yÄ± kapat ve hatayÄ± yÃ¼kselt
        browser.close()
        raise e 
    
    # OTP'yi Playwright ile giriÅŸ alanlarÄ±na parse et
    otp_inputs = page.locator("div.css-1phe0ka input")

    if len(otp_code) != otp_inputs.count():
        print(f"âš ï¸ UyarÄ±: DB'den Ã§ekilen OTP uzunluÄŸu ({len(otp_code)}) ile input sayÄ±sÄ± ({otp_inputs.count()}) uyuÅŸmuyor.")
    
    for i, digit in enumerate(otp_code):
        if i < otp_inputs.count():
             # Playwright ile her haneyi ilgili input'a yaz
            otp_inputs.nth(i).fill(digit) 

    print("âœ… OTP kodu Playwright ile dolduruldu.")

    # DoÄŸrula
    page.locator("button:has-text('DoÄŸrula')").click()
    page.wait_for_load_state("networkidle")
    print("â¡ï¸ OTP doÄŸrulandÄ±, yÃ¶nlendirme bekleniyor...")

    # Pentadijital â†’ Bayinet
    print("ğŸ” Mevcut URL (OTP sonrasÄ±):", page.url)
    page.wait_for_selector("span:has-text('Bayinet')", timeout=60000)
    print("â¡ï¸ Bayinet butonu bulundu, tÄ±klanÄ±yor...")
    page.click("span:has-text('Bayinet')")

    print("â³ Bayinet ana sayfasÄ±na yÃ¶nlendiriliyor...")
    page.wait_for_selector(".menu-categories__toggle.collapsed.js_collapsed.hidden-xs", timeout=120000)
    print("âœ… Bayinet ana sayfasÄ± tamamen yÃ¼klendi. URL:", page.url)

    return page


def run_scraper():
    print("ğŸš€ Bayinet Scraper baÅŸlÄ±yor...")

    with sync_playwright() as p:
        page = manual_login_and_get_session(p)

        print("âœ… Oturum hazÄ±r, scraping baÅŸlÄ±yor...")
        for i in range(1, 52):
            category_id = f"{i:02d}"
            print(f"\nğŸ“‚ Kategori {category_id} Ã§ekiliyor...")
            scrape_all_pages(page, category_id)

        print("âœ… Scraping tamamlandÄ±.")

if __name__ == "__main__":
    run_scraper()

