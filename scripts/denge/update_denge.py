import os
import re
import time
import json
from urllib.parse import urljoin
from dotenv import load_dotenv
from playwright.sync_api import sync_playwright
# scripts.shared.supabase_client dosyasÄ±nÄ±n var olduÄŸunu varsayÄ±yoruz
from scripts.shared.supabase_client import supabase 

# Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

# --- Sabitler ve Ayarlar ---
EMAIL = os.getenv("DENGE_EMAIL")
PASSWORD = os.getenv("DENGE_PASSWORD")
# YENÄ°: Proxy URL'sini ortam deÄŸiÅŸkeninden oku
PROXY_URL = os.getenv("TR_PROXY_URL") 
OTP_TABLE = "sms_codes"
BASE_URL = "https://www.edenge.com.tr"
TIMEOUT_SECONDS = 180

if not EMAIL or not PASSWORD:
    raise RuntimeError("ğŸš¨ .env dosyasÄ±nda DENGE_EMAIL ve DENGE_PASSWORD tanÄ±mlÄ± olmalÄ±!")

# --- Helper Fonksiyon: Fiyat Temizleme (DeÄŸiÅŸiklik yok) ---
def clean_price(price_str):
    if not price_str:
        return None
    try:
        cleaned_str = str(price_str).replace(".", "").replace(",", ".")
        return float(re.sub(r"[^\d.]", "", cleaned_str))
    except (ValueError, TypeError):
        return None

# --- Supabase OTP YÃ¶netimi (DeÄŸiÅŸiklik yok) ---
def get_and_clear_otp(timeout=TIMEOUT_SECONDS, poll_interval=5):
    # ... (Bu fonksiyonun iÃ§eriÄŸi aynÄ± kalmÄ±ÅŸtÄ±r)
    start_time = time.time()
    print(f"â³ {timeout} saniye boyunca DB'den OTP bekleniyor (Tablo: {OTP_TABLE})...")
    while time.time() - start_time < timeout:
        try:
            response = supabase.table(OTP_TABLE).select("otp_code").order("created_at", desc=True).limit(1).execute()
            if response.data and response.data[0] and response.data[0].get("otp_code"):
                otp_code = response.data[0]["otp_code"]
                print(f"âœ… OTP bulundu. ({int(time.time() - start_time)} saniye bekleme)")
                delete_response = supabase.table(OTP_TABLE).delete().eq("otp_code", otp_code).execute()
                print(f"ğŸ—‘ï¸ OTP veritabanÄ±ndan silindi. Silinen satÄ±r sayÄ±sÄ±: {len(delete_response.data)}")
                return otp_code
        except Exception as e:
            print(f"âš ï¸ Supabase OTP sorgu/silme hatasÄ±: {e}")
        time.sleep(poll_interval)
    raise TimeoutError(f"ğŸš¨ OTP {timeout} saniye iÃ§inde Supabase'e yazÄ±lmadÄ±, iÅŸlem iptal edildi.")


# --- Supabase kayÄ±t (Fiyat GeÃ§miÅŸi ile) - YENÄ° VE VERÄ°MLÄ° VERSÄ°YON ---
# --- Supabase kayÄ±t (Fiyat GeÃ§miÅŸi ile) - GÃœNCELLENMÄ°Å VE DÃœZELTÄ°LMÄ°Å VERSÄ°YON ---
def save_products_to_supabase(products, batch_size=50):
    """
    Sadece yeni veya fiyatÄ± deÄŸiÅŸen Ã¼rÃ¼nleri DB'ye yazar.
    Okuma iÅŸlemini de bÃ¼yÃ¼k veri setleri iÃ§in parÃ§alara bÃ¶ler.
    """
    if not products or not supabase:
        print("âŒ Supabase client eksik veya Ã¼rÃ¼n listesi boÅŸ. KayÄ±t atlandÄ±.")
        return

    product_ids = [p["product_id"] for p in products if p.get("product_id")]
    existing_products = {}
    
    # AdÄ±m 1: Mevcut Ã¼rÃ¼nlerin fiyat bilgilerini DB'den verimli ÅŸekilde Ã§ek
    SELECT_CHUNK_SIZE = 900
    if product_ids:
        print(f"ğŸ“Š DB'den {len(product_ids)} Ã¼rÃ¼nÃ¼n mevcut durumu sorgulanacak...")
        for i in range(0, len(product_ids), SELECT_CHUNK_SIZE):
            id_chunk = product_ids[i:i + SELECT_CHUNK_SIZE]
            try:
                response = supabase.table("denge_products").select("product_id,special_price").in_("product_id", id_chunk).execute()
                for item in response.data:
                    existing_products[item["product_id"]] = item
                print(f"   -> {len(response.data)} mevcut Ã¼rÃ¼n bilgisi alÄ±ndÄ± (grup {i//SELECT_CHUNK_SIZE + 1}).")
            except Exception as e:
                print(f"âš ï¸ Mevcut Ã¼rÃ¼nler Ã§ekilirken hata (grup {i//SELECT_CHUNK_SIZE + 1}): {e}")
        print(f"âœ… Toplam {len(existing_products)} mevcut Ã¼rÃ¼n bilgisi baÅŸarÄ±yla alÄ±ndÄ±.")

    # AdÄ±m 2: Sadece gÃ¼ncellenecek veya eklenecek Ã¼rÃ¼nleri belirle
    products_to_upsert = []
    print("\nğŸ” DeÄŸiÅŸiklikler kontrol ediliyor...")
    for p in products:
        product_id = p.get("product_id")
        if not product_id:
            continue

        # Durum 1: ÃœrÃ¼n veritabanÄ±nda yok (YENÄ° ÃœRÃœN)
        if product_id not in existing_products:
            print(f"âœ¨ Yeni Ã¼rÃ¼n bulundu: {p['name'][:60]}...")
            # Ã‡Ã–ZÃœM: Yeni Ã¼rÃ¼ne de 'last_price' alanÄ±nÄ± None olarak ekliyoruz.
            p['last_price'] = None
            products_to_upsert.append(p)
            continue
        
        # Durum 2: ÃœrÃ¼n veritabanÄ±nda var, fiyatlarÄ± karÅŸÄ±laÅŸtÄ±r
        old_price = existing_products[product_id].get("special_price")
        new_price = p.get("special_price")

        if old_price is not None and new_price is not None and old_price != new_price:
            p['last_price'] = old_price
            print(f"ğŸ’° Fiyat DeÄŸiÅŸti: {p['name'][:60]}... | Eski: {old_price} -> Yeni: {new_price}")
            products_to_upsert.append(p)

    # AdÄ±m 3: Sadece filtrelenmiÅŸ listeyi veritabanÄ±na yaz
    if not products_to_upsert:
        print("\nâœ… VeritabanÄ± gÃ¼ncel. Bu kategoride deÄŸiÅŸiklik veya yeni Ã¼rÃ¼n bulunamadÄ±.")
        return
        
    print(f"\nğŸ’¾ Toplam {len(products_to_upsert)} Ã¼rÃ¼nde deÄŸiÅŸiklik tespit edildi. VeritabanÄ± gÃ¼ncelleniyor...")
    for i in range(0, len(products_to_upsert), batch_size):
        chunk = products_to_upsert[i:i+batch_size]
        for attempt in range(3):
            try:
                data = (
                    supabase.table("denge_products")
                    .upsert(chunk, on_conflict="product_id")
                    .execute()
                )
                print(f"âœ… DB'ye {len(data.data)} Ã¼rÃ¼n yazÄ±ldÄ± (chunk {i//batch_size+1})")
                break
            except Exception as e:
                print(f"âš ï¸ Supabase error (chunk {i//batch_size+1}), retry {attempt+1}/3: {e}")
                time.sleep(5)

# --- Login + Otomatik OTP (Proxy AyarÄ± Eklendi) ---
# GÃœNCELLENDÄ°: Fonksiyon artÄ±k proxy_settings parametresi alÄ±yor
def eden_login(p, proxy_settings=None):
    launch_options = {
        "headless": True,
        "slow_mo": 50
    }
    # YENÄ°: EÄŸer proxy ayarÄ± varsa, baÅŸlatma seÃ§eneklerine ekle
    if proxy_settings:
        launch_options["proxy"] = proxy_settings
        print("ğŸš€ TarayÄ±cÄ± proxy ile baÅŸlatÄ±lÄ±yor...")
    
    browser = p.chromium.launch(**launch_options)
    context = browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36")
    page = context.new_page()
    page.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => false})")
    
    print("â¡ï¸ GiriÅŸ sayfasÄ±na gidiliyor...")
    page.goto(f"{BASE_URL}/Account/Login", wait_until="networkidle", timeout=60000)
    
    page.wait_for_selector("#username_", timeout=20000)
    page.fill("#username_", EMAIL)
    page.fill("#password_", PASSWORD)
    print("âœ… E-Posta ve Åifre dolduruldu.")
    
    page.click("button[type='submit']")
    print("ğŸš€ GiriÅŸ butonuna tÄ±klandÄ±, ana sayfanÄ±n yÃ¼klenmesi bekleniyor...")

    page.wait_for_selector("a.navigation-categories-item-title", timeout=60000)
    print("ğŸ Ana sayfa yÃ¼klendi, oturum hazÄ±r:", page.url)
    
    return page, browser

# --- ANA SCRAPER FONKSÄ°YONU (DeÄŸiÅŸiklik yok) ---
def scrape_category(page, category_name):
    # ... (Bu fonksiyonun iÃ§eriÄŸi aynÄ± kalmÄ±ÅŸtÄ±r)
    all_products = []
    page_count = 1
    while True:
        print(f"ğŸ“„ '{category_name}' kategorisi, sayfa {page_count} taranÄ±yor...")
        page.wait_for_selector(".table-row.js_basket_parents", timeout=30000)
        product_rows = page.query_selector_all(".table-row.js_basket_parents")
        print(f"   -> Bu sayfada {len(product_rows)} Ã¼rÃ¼n bulundu.")
        for row in product_rows:
            try:
                product_id = row.query_selector("input[name='cbxitem']").get_attribute("data-pid")
                name = row.query_selector(".title-cell h4").inner_text().strip()
                url_element = row.query_selector(".product-figure a")
                relative_url = url_element.get_attribute("href") if url_element else None
                stock = row.query_selector(".stock-status .stock").inner_text().strip()
                special_price_element = row.query_selector(".price-cell:not(.price-cell-last) .price")
                special_price_raw = special_price_element.get_attribute("data-pprice") if special_price_element else None
                list_price_element = row.query_selector(".price-cell-last .price")
                list_price_raw = list_price_element.get_attribute("data-pprice") if list_price_element else None
                currency_element = row.query_selector(".currency")
                currency = currency_element.inner_text().strip() if currency_element else "$"
                all_products.append({
                    "product_id": f"denge_{product_id}",
                    "name": name,
                    "special_price": clean_price(special_price_raw),
                    "list_price": clean_price(list_price_raw),
                    "currency": currency,
                    "stock_info": stock,
                    "category": category_name,
                    "url": urljoin(BASE_URL, relative_url) if relative_url else None,
                    "marketplace": "edenge",
                    "last_updated": time.strftime("%Y-%m-%d %H:%M:%S")
                })
            except Exception as e:
                print(f"âš ï¸ Bir Ã¼rÃ¼n satÄ±rÄ± iÅŸlenirken hata oluÅŸtu, atlanÄ±yor: {e}")
        next_page_button = page.query_selector("a.js_pagelink[rel='next']")
        if next_page_button:
            print("   -> Sonraki sayfa butonuna tÄ±klandÄ±.")
            next_page_button.click()
            page.wait_for_load_state("networkidle", timeout=60000)
            page_count += 1
        else:
            print(f"ğŸ '{category_name}' kategorisi iÃ§in son sayfaya ulaÅŸÄ±ldÄ±. Toplam {len(all_products)} Ã¼rÃ¼n Ã§ekildi.")
            break
    return all_products

# --- ANA Ã‡ALIÅTIRMA BLOÄU (Proxy AyarÄ± Eklendi) ---
# --- ANA Ã‡ALIÅTIRMA BLOÄU (TekilleÅŸtirme AdÄ±mÄ± Eklendi) ---
def run_scraper():
    print("ğŸš€ Edenge Scraper (DoÄŸrudan Veri Ã‡ekme Modu) baÅŸlÄ±yor...")
    
    proxy_config = None
    if PROXY_URL:
        proxy_config = {"server": PROXY_URL}
        proxy_host = PROXY_URL.split('@')[-1] if '@' in PROXY_URL else PROXY_URL
        print(f"âœ… Proxy yapÄ±landÄ±rÄ±ldÄ±: {proxy_host}")
    else:
        print("â„¹ï¸ Proxy ayarÄ± (TR_PROXY_URL) bulunamadÄ±. Direkt baÄŸlantÄ± kullanÄ±lacak.")

    try:
        with sync_playwright() as p:
            page, browser = eden_login(p, proxy_settings=proxy_config)
            
            category_elems = page.query_selector_all("a.navigation-categories-item-title")
            categories = []
            for elem in category_elems:
                href = elem.get_attribute("href")
                name = elem.inner_text().strip()
                if href and name:
                    categories.append((name, urljoin(BASE_URL, href)))
            
            print(f"ğŸ” {len(categories)} kategori bulundu.")
            for i, (cat_name, cat_url) in enumerate(categories, start=1):
                print(f"\nâ¡ï¸ {i}/{len(categories)}. Kategori BaÅŸlatÄ±lÄ±yor: {cat_name}")
                try:
                    page.goto(cat_url, wait_until="networkidle", timeout=60000)
                    
                    # 1. Scraper'dan Ã¼rÃ¼nleri Ã§ek
                    products = scrape_category(page, cat_name)
                    
                    # --- YENÄ°: TEKÄ°LLEÅTÄ°RME ADIMI ---
                    if products:
                        print(f"   -> TekilleÅŸtirme Ã¶ncesi Ã¼rÃ¼n sayÄ±sÄ±: {len(products)}")
                        unique_products = {}
                        for product in products:
                            # Her bir Ã¼rÃ¼nÃ¼ product_id'yi anahtar olarak kullanarak bir sÃ¶zlÃ¼ÄŸe ekle.
                            # EÄŸer aynÄ± product_id tekrar gelirse, eski kaydÄ±n Ã¼zerine yazar.
                            # Bu, listedeki son gÃ¶rÃ¼len Ã¼rÃ¼nÃ¼n geÃ§erli olmasÄ±nÄ± saÄŸlar.
                            unique_products[product['product_id']] = product
                        
                        # SÃ¶zlÃ¼ÄŸÃ¼n deÄŸerlerini (tekilleÅŸtirilmiÅŸ Ã¼rÃ¼nleri) tekrar bir listeye Ã§evir.
                        products = list(unique_products.values())
                        print(f"   -> TekilleÅŸtirme sonrasÄ± Ã¼rÃ¼n sayÄ±sÄ±: {len(products)}")
                    # --- TEKÄ°LLEÅTÄ°RME ADIMI SONU ---

                    if products:
                        # 2. Sadece tekilleÅŸtirilmiÅŸ listeyi veritabanÄ±na gÃ¶nder
                        save_products_to_supabase(products)
                    else:
                        print(f"â„¹ï¸ '{cat_name}' kategorisinden hiÃ§ Ã¼rÃ¼n Ã§ekilemedi.")
                except Exception as e:
                    print(f"ğŸš¨ Kategori '{cat_name}' iÅŸlenirken kritik bir hata oluÅŸtu: {e}")
            
            browser.close()
            print("\nâœ… TÃ¼m kategoriler baÅŸarÄ±yla iÅŸlendi. Script tamamlandÄ±.")
    except Exception as e:
        print(f"ğŸ”¥ğŸ”¥ Kritik hata, tarayÄ±cÄ± baÅŸlatÄ±lamadÄ± veya oturum aÃ§Ä±lamadÄ±: {e}")

if __name__ == "__main__":
    run_scraper()